#!/usr/bin/env python3
"""
Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… + Ğ°Ñ‚Ğ°ĞºĞ¸ Ğ½Ğ° Ğ½ĞµĞ²Ğ¸Ğ´Ğ¸Ğ¼Ñ‹Ğµ Ğ²Ğ¾Ğ´ÑĞ½Ñ‹Ğµ Ğ·Ğ½Ğ°ĞºĞ¸ (SynthID Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¸).
Ğ”Ğ»Ñ Ğ½Ğ°ÑƒÑ‡Ğ½Ğ¾-Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ñ… Ñ†ĞµĞ»ĞµĞ¹ (Ğ¼ĞµĞ´Ğ¸Ğ°Ñ„Ğ¾Ñ€ĞµĞ½Ğ·Ğ¸ĞºĞ°, watermark robustness).

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
 Ğ§Ğ¢Ğ Ğ”Ğ•Ğ›ĞĞ•Ğ¢ Ğ¡ĞšĞ Ğ˜ĞŸĞ¢:
   1. Ğ£Ğ´Ğ°Ğ»ÑĞµÑ‚ Ğ²ÑĞµ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ (EXIF/XMP/IPTC/chunks)
   2. ĞÑ‚Ğ°ĞºÑƒĞµÑ‚ Ğ½ĞµĞ²Ğ¸Ğ´Ğ¸Ğ¼Ñ‹Ğµ Ğ²Ğ¾Ğ´ÑĞ½Ñ‹Ğµ Ğ·Ğ½Ğ°ĞºĞ¸ (SynthID, C2PA, HiDDeN, Ğ¸ Ğ´Ñ€.)
      Ñ‡ĞµÑ€ĞµĞ· Ğ½Ğ°Ğ±Ğ¾Ñ€ Ñ‚ĞµÑ…Ğ½Ğ¸Ğº Ğ¸Ğ· Ğ°ĞºĞ°Ğ´ĞµĞ¼Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ»Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ñ‹

 Ğ¢Ğ•Ğ¥ĞĞ˜ĞšĞ˜ ĞĞ¢ĞĞš ĞĞ WATERMARK:
   - Gaussian noise injection          (ĞºĞ»Ğ°ÑÑĞ¸ĞºĞ°, Stirmark)
   - JPEG double compression           (Ğ°Ñ‚Ğ°ĞºĞ° Ğ½Ğ° Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ½Ñ‹Ğ¹ Ğ´Ğ¾Ğ¼ĞµĞ½)
   - DCT-coefficient perturbation      (Ğ¿Ñ€ÑĞ¼Ğ°Ñ Ğ°Ñ‚Ğ°ĞºĞ° Ğ½Ğ° Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ñ‹)
   - Wavelet-domain noise              (Ğ°Ñ‚Ğ°ĞºĞ° Ñ‡ĞµÑ€ĞµĞ· DWT)
   - Brightness/contrast jitter        (Ñ„Ğ¾Ñ‚Ğ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸)
   - Geometric micro-distortion        (ÑÑƒĞ±Ğ¿Ğ¸ĞºÑĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ´ĞµÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸)
   - Median filter                     (ÑĞ³Ğ»Ğ°Ğ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ watermark-Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ¾Ğ²)
   - FGSM-style adversarial noise      (Goodfellow et al., 2014)
   - Combined ensemble attack          (Ğ²ÑĞµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ²Ğ¼ĞµÑÑ‚Ğµ)

 Ğ¡Ğ¡Ğ«Ğ›ĞšĞ˜:
   Fernandez et al. "The Stable Signature" (2023)
   Zhao et al. "Invisible Image Watermarks Are Provably Removable" (2023)
   Saberi et al. "Robustness of AI-Image Detectors" (2023)
   Yang et al. "Gaussian Shading" (2024)

 Ğ—ĞĞ’Ğ˜Ğ¡Ğ˜ĞœĞĞ¡Ğ¢Ğ˜:
   pip install Pillow numpy scipy pywavelets
   pip install torch torchvision   # Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾, Ğ´Ğ»Ñ FGSM
   ffmpeg  â€” https://ffmpeg.org
   exiftool â€” https://exiftool.org
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""

import os
import sys
import shutil
import struct
import subprocess
import argparse
import random
import json
import math
import tempfile
from pathlib import Path
from datetime import datetime
from io import BytesIO

import numpy as np

try:
    from PIL import Image, ImageFilter
    HAS_PIL = True
except ImportError:
    HAS_PIL = False
    print("[!] Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ Pillow: pip install Pillow")

try:
    from scipy import ndimage
    HAS_SCIPY = True
except ImportError:
    HAS_SCIPY = False

try:
    import pywt
    HAS_WAVELETS = True
except ImportError:
    HAS_WAVELETS = False


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Ğ£Ğ¢Ğ˜Ğ›Ğ˜Ğ¢Ğ«
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run(cmd, capture=True):
    r = subprocess.run(cmd, capture_output=capture, text=True)
    return r.returncode == 0, r.stderr


def has_tool(name):
    return shutil.which(name) is not None


def randomize_timestamps(path: Path):
    ts = random.uniform(
        datetime(2020, 1, 1).timestamp(),
        datetime(2024, 12, 31).timestamp()
    )
    os.utime(path, (ts, ts))


def img_to_array(img: "Image.Image") -> np.ndarray:
    return np.array(img, dtype=np.float32)


def array_to_img(arr: np.ndarray, mode="RGB") -> "Image.Image":
    arr = np.clip(arr, 0, 255).astype(np.uint8)
    return Image.fromarray(arr, mode)


def psnr(original: np.ndarray, modified: np.ndarray) -> float:
    """Peak Signal-to-Noise Ratio â€” Ğ¼ĞµÑ€Ğ° ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ¿Ğ¾ÑĞ»Ğµ Ğ°Ñ‚Ğ°ĞºĞ¸."""
    mse = np.mean((original - modified) ** 2)
    if mse == 0:
        return float("inf")
    return 20 * math.log10(255.0 / math.sqrt(mse))


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  ĞĞ¢ĞĞšĞ˜ ĞĞ ĞĞ•Ğ’Ğ˜Ğ”Ğ˜ĞœĞ«Ğ• Ğ’ĞĞ”Ğ¯ĞĞ«Ğ• Ğ—ĞĞĞšĞ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class WatermarkAttacker:
    """
    ĞĞ°Ğ±Ğ¾Ñ€ Ğ°Ñ‚Ğ°Ğº Ğ½Ğ° invisible watermarks (SynthID, HiDDeN, RivaGAN, TrustMark Ğ¸ Ğ´Ñ€.)
    ĞšĞ°Ğ¶Ğ´Ğ°Ñ Ğ°Ñ‚Ğ°ĞºĞ° Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾ Ğ´ĞµĞ³Ñ€Ğ°Ğ´Ğ¸Ñ€ÑƒĞµÑ‚ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğµ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾, Ğ½Ğ¾ Ğ½Ğ°Ñ€ÑƒÑˆĞ°ĞµÑ‚
    ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹, Ğ² ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… Ğ·Ğ°ĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ Ğ²Ğ¾Ğ´ÑĞ½Ğ¾Ğ¹ Ğ·Ğ½Ğ°Ğº.
    """

    def __init__(self, strength: float = 0.5, verbose: bool = False):
        """
        strength: 0.0â€“1.0, Ğ³Ğ´Ğµ 0.0 = Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ²Ğ¾Ğ·Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ, 1.0 = Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ.
        Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ 0.3â€“0.6 Ğ´Ğ»Ñ Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ° ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾/ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ.
        """
        self.strength = strength
        self.verbose = verbose

    def _log(self, msg):
        if self.verbose:
            print(f"    [wm] {msg}")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 1. Ğ“Ğ°ÑƒÑÑĞ¾Ğ²ÑĞºĞ¸Ğ¹ ÑˆÑƒĞ¼ (Stirmark-style)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def gaussian_noise(self, arr: np.ndarray) -> np.ndarray:
        """
        Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ“Ğ°ÑƒÑÑĞ¾Ğ²ÑĞºĞ¸Ğ¹ ÑˆÑƒĞ¼ Ñ Ïƒ Ğ¿Ñ€Ğ¾Ğ¿Ğ¾Ñ€Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼ strength.
        ĞĞ°Ñ€ÑƒÑˆĞ°ĞµÑ‚ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ½Ñ‹Ğµ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ watermark Ğ±ĞµĞ· Ğ²Ğ¸Ğ´Ğ¸Ğ¼Ğ¾Ğ¹ Ğ´ĞµĞ³Ñ€Ğ°Ğ´Ğ°Ñ†Ğ¸Ğ¸.
        Ref: Stirmark Benchmark (Petitcolas et al., 1998)
        """
        sigma = self.strength * 8.0  # Ïƒ âˆˆ [0, 8] Ğ¿Ñ€Ğ¸ strength âˆˆ [0, 1]
        noise = np.random.normal(0, sigma, arr.shape)
        self._log(f"Gaussian noise Ïƒ={sigma:.2f}")
        return arr + noise

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 2. ĞÑ‚Ğ°ĞºĞ° Ñ‡ĞµÑ€ĞµĞ· Ğ´Ğ²Ğ¾Ğ¹Ğ½Ğ¾Ğµ JPEG-ÑĞ¶Ğ°Ñ‚Ğ¸Ğµ
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def double_jpeg(self, img: "Image.Image") -> "Image.Image":
        """
        Ğ”Ğ²Ğ¾Ğ¹Ğ½Ğ¾Ğµ JPEG-ÑĞ¶Ğ°Ñ‚Ğ¸Ğµ Ñ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğ¼Ğ¸ quality factor'Ğ°Ğ¼Ğ¸.
        DCT-ĞºĞ²Ğ°Ğ½Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ€Ğ°Ğ·Ñ€ÑƒÑˆĞ°ĞµÑ‚ Ñ‚Ğ¾Ğ½ĞºĞ¸Ğµ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ½Ñ‹Ğµ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ watermark.
        Ref: Ğšlassic Ğ°Ñ‚Ğ°ĞºĞ°, Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ° Ğ² Barni et al. (2001)
        """
        q1 = int(85 - self.strength * 20)  # 65â€“85
        q2 = int(90 - self.strength * 10)  # 80â€“90

        buf = BytesIO()
        img.save(buf, format="JPEG", quality=q1, subsampling=0)
        buf.seek(0)
        img2 = Image.open(buf).copy()

        buf2 = BytesIO()
        img2.save(buf2, format="JPEG", quality=q2, subsampling=0)
        buf2.seek(0)
        result = Image.open(buf2).copy()

        self._log(f"Double JPEG: q1={q1}, q2={q2}")
        return result

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 3. ĞŸÑ€ÑĞ¼Ğ°Ñ Ğ°Ñ‚Ğ°ĞºĞ° Ğ½Ğ° DCT-ĞºĞ¾ÑÑ„Ñ„Ğ¸Ñ†Ğ¸ĞµĞ½Ñ‚Ñ‹
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def dct_perturbation(self, arr: np.ndarray) -> np.ndarray:
        """
        Ğ’Ğ½Ğ¾ÑĞ¸Ñ‚ Ğ²Ğ¾Ğ·Ğ¼ÑƒÑ‰ĞµĞ½Ğ¸Ñ Ğ² DCT-ĞºĞ¾ÑÑ„Ñ„Ğ¸Ñ†Ğ¸ĞµĞ½Ñ‚Ñ‹ ÑÑ€ĞµĞ´Ğ½Ğ¸Ñ… Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚ Ğ±Ğ»Ğ¾ĞºĞ°Ğ¼Ğ¸ 8Ã—8.
        ĞÑ‚Ğ°ĞºÑƒĞµÑ‚ Ğ¸Ğ¼ĞµĞ½Ğ½Ğ¾ Ñ‚Ğµ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ñ‹, Ğ³Ğ´Ğµ Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ğ¾ Ğ²ÑÑ‚Ñ€Ğ°Ğ¸Ğ²Ğ°ĞµÑ‚ÑÑ watermark.
        Ref: Cox et al. "Watermarking as communications with side information" (1999)
        """
        result = arr.copy()
        h, w = arr.shape[:2]
        epsilon = self.strength * 3.0

        for c in range(arr.shape[2]):
            for y in range(0, h - 8, 8):
                for x in range(0, w - 8, 8):
                    block = result[y:y+8, x:x+8, c]
                    # DCT Ğ±Ğ»Ğ¾ĞºĞ°
                    dct_block = self._dct2(block)
                    # Ğ’Ğ¾Ğ·Ğ¼ÑƒÑ‰Ğ°ĞµĞ¼ ÑÑ€ĞµĞ´Ğ½Ğ¸Ğµ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ñ‹ (Ğ·Ğ¾Ğ½Ğ° watermark)
                    perturbation = np.random.uniform(-epsilon, epsilon, (8, 8))
                    # ĞœĞ°ÑĞºĞ° ÑÑ€ĞµĞ´Ğ½Ğ¸Ñ… Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚ (Ğ¸Ğ·Ğ±ĞµĞ³Ğ°ĞµĞ¼ DC Ğ¸ Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ğµ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ñ‹)
                    mask = np.zeros((8, 8))
                    mask[1:5, 1:5] = 1.0
                    dct_block += perturbation * mask
                    # ĞĞ±Ñ€Ğ°Ñ‚Ğ½Ğ¾Ğµ DCT
                    result[y:y+8, x:x+8, c] = self._idct2(dct_block)

        self._log(f"DCT perturbation Îµ={epsilon:.2f}")
        return result

    def _dct2(self, block: np.ndarray) -> np.ndarray:
        """2D DCT Ñ‡ĞµÑ€ĞµĞ· Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ¸Ğ¼Ñ‹Ğµ 1D DCT."""
        from scipy.fft import dct
        return dct(dct(block.T, norm='ortho').T, norm='ortho')

    def _idct2(self, block: np.ndarray) -> np.ndarray:
        """2D Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾Ğµ DCT."""
        from scipy.fft import idct
        return idct(idct(block.T, norm='ortho').T, norm='ortho')

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 4. ĞÑ‚Ğ°ĞºĞ° Ñ‡ĞµÑ€ĞµĞ· Ğ²ĞµĞ¹Ğ²Ğ»ĞµÑ‚-Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ (DWT)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def wavelet_noise(self, arr: np.ndarray) -> np.ndarray:
        """
        Ğ’Ğ½Ğ¾ÑĞ¸Ñ‚ ÑˆÑƒĞ¼ Ğ² Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ½Ñ‹Ğµ Ğ²ĞµĞ¹Ğ²Ğ»ĞµÑ‚-ĞºĞ¾ÑÑ„Ñ„Ğ¸Ñ†Ğ¸ĞµĞ½Ñ‚Ñ‹ (Ğ´ĞµÑ‚Ğ°Ğ»Ğ¸).
        SynthID Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¸ Ñ‡Ğ°ÑÑ‚Ğ¾ ĞºĞ¾Ğ´Ğ¸Ñ€ÑƒÑÑ‚ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ² HH/HL/LH ÑÑƒĞ±Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ğ°Ñ….
        Ref: Jiang et al. "WEvader" (2023)
        """
        if not HAS_WAVELETS:
            self._log("pywt Ğ½Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½, Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞº DWT-Ğ°Ñ‚Ğ°ĞºĞ¸")
            return arr

        result = arr.copy()
        epsilon = self.strength * 5.0

        for c in range(arr.shape[2]):
            coeffs = pywt.dwt2(result[:, :, c], 'db4')
            cA, (cH, cV, cD) = coeffs

            # ĞÑ‚Ğ°ĞºÑƒĞµĞ¼ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ ĞºĞ¾ÑÑ„Ñ„Ğ¸Ñ†Ğ¸ĞµĞ½Ñ‚Ñ‹ (Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ğµ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ñ‹)
            cH += np.random.normal(0, epsilon, cH.shape)
            cV += np.random.normal(0, epsilon, cV.shape)
            cD += np.random.normal(0, epsilon, cD.shape)

            result[:, :, c] = pywt.idwt2((cA, (cH, cV, cD)), 'db4')

        self._log(f"Wavelet noise Îµ={epsilon:.2f}")
        return result

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 5. Ğ¤Ğ¾Ñ‚Ğ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def photometric_jitter(self, arr: np.ndarray) -> np.ndarray:
        """
        Ğ¡Ğ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ğµ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ ÑÑ€ĞºĞ¾ÑÑ‚Ğ¸, ĞºĞ¾Ğ½Ñ‚Ñ€Ğ°ÑÑ‚Ğ° Ğ¸ Ğ³Ğ°Ğ¼Ğ¼Ñ‹.
        ĞĞ°Ñ€ÑƒÑˆĞ°ÑÑ‚ Ğ°Ğ±ÑĞ¾Ğ»ÑÑ‚Ğ½Ñ‹Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ Ğ¿Ğ¸ĞºÑĞµĞ»ĞµĞ¹, Ğ² ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… Ğ·Ğ°ĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ WM.
        """
        result = arr.copy()

        # Ğ“Ğ°Ğ¼Ğ¼Ğ°-ĞºĞ¾Ñ€Ñ€ĞµĞºÑ†Ğ¸Ñ
        gamma = 1.0 + (random.random() - 0.5) * self.strength * 0.3
        result = np.power(result / 255.0, gamma) * 255.0

        # Ğ¯Ñ€ĞºĞ¾ÑÑ‚ÑŒ
        brightness = (random.random() - 0.5) * self.strength * 15
        result += brightness

        # ĞšĞ¾Ğ½Ñ‚Ñ€Ğ°ÑÑ‚
        contrast = 1.0 + (random.random() - 0.5) * self.strength * 0.2
        mean = np.mean(result)
        result = (result - mean) * contrast + mean

        self._log(f"Photometric jitter: Î³={gamma:.3f}, b={brightness:.1f}, c={contrast:.3f}")
        return result

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 6. Ğ“ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¼Ğ¸ĞºÑ€Ğ¾-Ğ´ĞµÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def geometric_distortion(self, arr: np.ndarray) -> np.ndarray:
        """
        Ğ¡ÑƒĞ±Ğ¿Ğ¸ĞºÑĞµĞ»ÑŒĞ½Ñ‹Ğµ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ğµ Ğ´ĞµÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ (displacement field).
        ĞĞ°Ñ€ÑƒÑˆĞ°ÑÑ‚ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸, Ğ½Ğ° ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½ WM.
        Ref: Stirmark random bend (Petitcolas et al., 1998)
        """
        if not HAS_SCIPY:
            return arr

        h, w = arr.shape[:2]
        amplitude = self.strength * 1.5  # Ğ² Ğ¿Ğ¸ĞºÑĞµĞ»ÑÑ…

        # Ğ¡Ğ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ğ¾Ğµ Ğ¿Ğ¾Ğ»Ğµ ÑĞ¼ĞµÑ‰ĞµĞ½Ğ¸Ğ¹
        dy = ndimage.gaussian_filter(
            np.random.randn(h, w) * amplitude, sigma=3
        )
        dx = ndimage.gaussian_filter(
            np.random.randn(h, w) * amplitude, sigma=3
        )

        y_coords, x_coords = np.mgrid[0:h, 0:w]
        y_new = np.clip(y_coords + dy, 0, h - 1).astype(np.float32)
        x_new = np.clip(x_coords + dx, 0, w - 1).astype(np.float32)

        result = np.zeros_like(arr)
        for c in range(arr.shape[2]):
            result[:, :, c] = ndimage.map_coordinates(
                arr[:, :, c], [y_new, x_new], order=1, mode='reflect'
            )

        self._log(f"Geometric distortion amplitude={amplitude:.2f}px")
        return result

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 7. ĞœĞµĞ´Ğ¸Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def median_filter(self, img: "Image.Image") -> "Image.Image":
        """
        ĞĞµĞ»Ğ¸Ğ½ĞµĞ¹Ğ½Ñ‹Ğ¹ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€, ÑƒĞ½Ğ¸Ñ‡Ñ‚Ğ¾Ğ¶Ğ°ĞµÑ‚ Ñ‚Ğ¾Ğ½ĞºĞ¸Ğµ Ğ¿Ğ¸ĞºÑĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹.
        Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²ĞµĞ½ Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ² LSB-based Ğ¸ pixel-level watermarks.
        """
        size = 3 if self.strength < 0.5 else 5
        self._log(f"Median filter size={size}Ã—{size}")
        return img.filter(ImageFilter.MedianFilter(size=size))

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 8. FGSM-style adversarial noise
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def fgsm_noise(self, arr: np.ndarray) -> np.ndarray:
        """
        Fast Gradient Sign Method (Goodfellow et al., 2014) Ğ±ĞµĞ· Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸.
        ĞĞ¿Ğ¿Ñ€Ğ¾ĞºÑĞ¸Ğ¼Ğ°Ñ†Ğ¸Ñ: ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ ÑˆÑƒĞ¼ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ·Ğ½Ğ°ĞºĞ° Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ°
        Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ²Ğ°Ñ€Ğ¸Ğ°Ñ†Ğ¸Ğ¸ â€” Ğ½Ğ°Ñ€ÑƒÑˆĞ°ĞµÑ‚ Ğ´ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€ Ğ±ĞµĞ· Ğ·Ğ½Ğ°Ñ‡Ğ¸Ğ¼Ğ¾Ğ³Ğ¾ PSNR-ÑĞ½Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ.
        Ref: Zhao et al. "Invisible Image Watermarks Are Provably Removable" (2023)
        """
        epsilon = self.strength * 4.0

        # ĞĞ¿Ğ¿Ñ€Ğ¾ĞºÑĞ¸Ğ¼Ğ°Ñ†Ğ¸Ñ "Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ°" Ñ‡ĞµÑ€ĞµĞ· Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½ÑƒÑ Ğ²Ğ°Ñ€Ğ¸Ğ°Ñ†Ğ¸Ñ (Sobel)
        result = arr.copy()
        for c in range(arr.shape[2]):
            # Sobel-Ğ°Ğ¿Ğ¿Ñ€Ğ¾ĞºÑĞ¸Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ°
            gy = np.gradient(arr[:, :, c], axis=0)
            gx = np.gradient(arr[:, :, c], axis=1)
            grad = gy + gx
            # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ·Ğ½Ğ°Ğº Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ° (FGSM)
            result[:, :, c] += epsilon * np.sign(grad)

        self._log(f"FGSM-style adversarial noise Îµ={epsilon:.2f}")
        return result

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 9. Ensemble-Ğ°Ñ‚Ğ°ĞºĞ° (Ğ²ÑĞµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def ensemble_attack(self, img: "Image.Image") -> "Image.Image":
        """
        ĞŸĞ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ Ğ²ÑĞµÑ… Ğ°Ñ‚Ğ°Ğº Ñ Ğ¿Ğ¾Ğ½Ğ¸Ğ¶ĞµĞ½Ğ½Ñ‹Ğ¼ strength.
        ĞĞ°Ğ¸Ğ±Ğ¾Ğ»ĞµĞµ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ°Ñ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ğ´Ğ»Ñ Ğ¾Ğ±Ñ…Ğ¾Ğ´Ğ° robustness watermarks.
        Ref: Saberi et al. "Robustness of AI-Image Detectors" (2023)
        """
        self._log("=== ENSEMBLE ATTACK ===")
        original_strength = self.strength
        # Ğ¡Ğ½Ğ¸Ğ¶Ğ°ĞµĞ¼ ÑĞ¸Ğ»Ñƒ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ°Ñ‚Ğ°ĞºĞ¸, Ñ‚.Ğº. Ğ¾Ğ½Ğ¸ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑÑÑ‚ÑÑ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ½Ğ¾
        self.strength = original_strength * 0.4

        arr = img_to_array(img)
        original_arr = arr.copy()

        # Ğ¨Ğ°Ğ³ 1: Ğ¤Ğ¾Ñ‚Ğ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸
        arr = self.photometric_jitter(arr)

        # Ğ¨Ğ°Ğ³ 2: Ğ’ĞµĞ¹Ğ²Ğ»ĞµÑ‚-ÑˆÑƒĞ¼
        if HAS_WAVELETS:
            arr = self.wavelet_noise(arr)

        # Ğ¨Ğ°Ğ³ 3: Ğ“ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ´ĞµÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸
        if HAS_SCIPY:
            arr = self.geometric_distortion(arr)

        # Ğ¨Ğ°Ğ³ 4: FGSM-ÑˆÑƒĞ¼
        arr = self.fgsm_noise(arr)

        # Ğ¨Ğ°Ğ³ 5: Ğ“Ğ°ÑƒÑÑĞ¾Ğ²ÑĞºĞ¸Ğ¹ ÑˆÑƒĞ¼
        arr = self.gaussian_noise(arr)

        img_result = array_to_img(arr, img.mode)

        # Ğ¨Ğ°Ğ³ 6: ĞœĞµĞ´Ğ¸Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€
        img_result = self.median_filter(img_result)

        # Ğ¨Ğ°Ğ³ 7: DCT-Ğ²Ğ¾Ğ·Ğ¼ÑƒÑ‰ĞµĞ½Ğ¸Ñ (ĞµÑĞ»Ğ¸ scipy Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½)
        if HAS_SCIPY:
            arr2 = img_to_array(img_result)
            arr2 = self.dct_perturbation(arr2)
            img_result = array_to_img(arr2, img.mode)

        # Ğ¨Ğ°Ğ³ 8: Ğ”Ğ²Ğ¾Ğ¹Ğ½Ğ¾Ğµ JPEG (Ñ„Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ)
        img_result = self.double_jpeg(img_result)

        # ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ° ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°
        final_arr = img_to_array(img_result)
        score = psnr(original_arr, final_arr)
        self._log(f"PSNR Ğ¿Ğ¾ÑĞ»Ğµ ensemble: {score:.2f} dB "
                  f"({'Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ½Ğ¾Ğµ' if score > 40 else 'Ñ…Ğ¾Ñ€Ğ¾ÑˆĞµĞµ' if score > 35 else 'Ğ·Ğ°Ğ¼ĞµÑ‚Ğ½Ğ¾Ğµ'} ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾)")

        self.strength = original_strength
        return img_result

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ĞŸÑ€Ğ¸Ğ¼ĞµĞ½Ğ¸Ñ‚ÑŒ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½ÑƒÑ Ğ°Ñ‚Ğ°ĞºÑƒ
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def apply(self, img: "Image.Image", method: str) -> "Image.Image":
        """ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑĞµÑ‚ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğº Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ."""
        if img.mode != "RGB":
            img = img.convert("RGB")

        if method == "ensemble":
            return self.ensemble_attack(img)

        arr = img_to_array(img)

        if method == "gaussian":
            arr = self.gaussian_noise(arr)
        elif method == "dct":
            if HAS_SCIPY:
                arr = self.dct_perturbation(arr)
            else:
                print("    [!] scipy Ğ½ÑƒĞ¶ĞµĞ½ Ğ´Ğ»Ñ DCT-Ğ°Ñ‚Ğ°ĞºĞ¸: pip install scipy")
                return img
        elif method == "wavelet":
            arr = self.wavelet_noise(arr)
        elif method == "photometric":
            arr = self.photometric_jitter(arr)
        elif method == "geometric":
            if HAS_SCIPY:
                arr = self.geometric_distortion(arr)
            else:
                print("    [!] scipy Ğ½ÑƒĞ¶ĞµĞ½ Ğ´Ğ»Ñ geometric-Ğ°Ñ‚Ğ°ĞºĞ¸: pip install scipy")
                return img
        elif method == "fgsm":
            arr = self.fgsm_noise(arr)
        else:
            print(f"    [!] ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´: {method}")
            return img

        result_img = array_to_img(arr, "RGB")

        if method == "median":
            result_img = self.median_filter(result_img)
        if method in ("jpeg", "double_jpeg"):
            result_img = self.double_jpeg(result_img)

        return result_img


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Ğ£Ğ”ĞĞ›Ğ•ĞĞ˜Ğ• ĞœĞ•Ğ¢ĞĞ”ĞĞĞĞ«Ğ¥ (JPEG / PNG Ğ½Ğ¸Ğ·ĞºĞ¸Ğ¹ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def strip_jpeg(input_path: Path, output_path: Path) -> bool:
    with open(input_path, "rb") as f:
        data = f.read()
    if data[:2] != b"\xff\xd8":
        return False

    output = BytesIO()
    output.write(b"\xff\xd8")
    i = 2
    while i < len(data):
        if data[i] != 0xFF:
            break
        marker = data[i:i+2]
        i += 2
        if marker in (b"\xff\xd9", b"\xff\xd8"):
            output.write(marker)
            continue
        if marker == b"\xff\xda":
            output.write(marker)
            output.write(data[i:])
            break
        if i + 2 > len(data):
            break
        length = struct.unpack(">H", data[i:i+2])[0]
        segment_data = data[i:i + length]
        i += length
        if b"\xff\xe0" <= marker <= b"\xff\xef":
            continue
        if marker == b"\xff\xfe":
            continue
        output.write(marker)
        output.write(segment_data)

    with open(output_path, "wb") as f:
        f.write(output.getvalue())
    return True


def strip_png(input_path: Path, output_path: Path) -> bool:
    SKIP = {b"tEXt", b"iTXt", b"zTXt", b"tIME", b"eXIf",
            b"iCCP", b"cHRM", b"gAMA", b"sRGB", b"sBIT",
            b"bKGD", b"hIST", b"sPLT", b"pHYs"}
    PNG_SIG = b"\x89PNG\r\n\x1a\n"

    with open(input_path, "rb") as f:
        data = f.read()
    if data[:8] != PNG_SIG:
        return False

    output = BytesIO()
    output.write(PNG_SIG)
    i = 8
    while i < len(data):
        if i + 12 > len(data):
            break
        length = struct.unpack(">I", data[i:i+4])[0]
        chunk_type = data[i+4:i+8]
        chunk_end = i + 12 + length
        if chunk_type not in SKIP:
            output.write(data[i:chunk_end])
        i = chunk_end

    with open(output_path, "wb") as f:
        f.write(output.getvalue())
    return True


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  ĞĞ‘Ğ ĞĞ‘ĞĞ¢ĞšĞ Ğ˜Ğ—ĞĞ‘Ğ ĞĞ–Ğ•ĞĞ˜Ğ¯ (Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ + watermark)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def process_image(
    input_path: Path,
    output_path: Path,
    wm_method: str = "ensemble",
    wm_strength: float = 0.5,
    aggressive_meta: bool = False,
    verbose: bool = False
) -> bool:
    if not HAS_PIL:
        return False

    ext = input_path.suffix.lower()
    print(f"    Ğ¨Ğ°Ğ³ 1: Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…...")

    # --- Ğ¨Ğ°Ğ³ 1: Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… ---
    meta_ok = False

    if has_tool("exiftool"):
        ok, _ = run(["exiftool", "-all=", "-overwrite_original",
                     "-o", str(output_path), str(input_path)])
        if ok:
            print(f"    [exiftool] Ğ’ÑĞµ Ñ‚ĞµĞ³Ğ¸ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ñ‹")
            meta_ok = True

    if not meta_ok:
        if ext in (".jpg", ".jpeg"):
            meta_ok = strip_jpeg(input_path, output_path)
            if meta_ok:
                print(f"    [jpeg-strip] APP-ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ñ‹ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ñ‹")
        elif ext == ".png":
            meta_ok = strip_png(input_path, output_path)
            if meta_ok:
                print(f"    [png-strip] Metadata-Ñ‡Ğ°Ğ½ĞºĞ¸ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ñ‹")

    if not meta_ok:
        # Pillow fallback
        with Image.open(input_path) as img:
            fmt = (img.format or ext.lstrip(".")).upper()
            if fmt == "JPG":
                fmt = "JPEG"
            img.convert("RGB").save(output_path, format=fmt, quality=95)
        print(f"    [pillow] ĞœĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ñ‹ Ğ¿Ñ€Ğ¸ Ğ¿ĞµÑ€ĞµÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğ¸")
        meta_ok = True

    # --- Ğ¨Ğ°Ğ³ 2: ĞÑ‚Ğ°ĞºĞ° Ğ½Ğ° watermark ---
    print(f"    Ğ¨Ğ°Ğ³ 2: ĞÑ‚Ğ°ĞºĞ° Ğ½Ğ° watermark (Ğ¼ĞµÑ‚Ğ¾Ğ´={wm_method}, strength={wm_strength})...")

    attacker = WatermarkAttacker(strength=wm_strength, verbose=verbose)

    with Image.open(output_path) as img:
        img_copy = img.copy()

    original_arr = img_to_array(img_copy.convert("RGB"))

    attacked_img = attacker.apply(img_copy, wm_method)

    # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚
    save_path = output_path
    fmt = ext.lstrip(".").upper()
    if fmt == "JPG":
        fmt = "JPEG"

    save_kw = {}
    if fmt == "JPEG":
        save_kw = {"quality": 95, "optimize": True, "subsampling": 0}
    elif fmt == "PNG":
        save_kw = {"optimize": True}

    attacked_img.save(save_path, format=fmt, **save_kw)

    # Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´ ExifTool (Ğ°Ñ‚Ğ°ĞºĞ° Ğ¼Ğ¾Ğ³Ğ»Ğ° Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ñ‚ĞµĞ³Ğ¸)
    if has_tool("exiftool"):
        run(["exiftool", "-all=", "-overwrite_original", str(save_path)])

    # ĞÑ‚Ñ‡Ñ‘Ñ‚ Ğ¾ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğµ
    final_arr = img_to_array(Image.open(save_path).convert("RGB"))
    score = psnr(original_arr, final_arr)
    quality_label = (
        "Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ½Ğ¾Ğµ (Ğ½ĞµĞ·Ğ°Ğ¼ĞµÑ‚Ğ½Ğ¾)" if score > 42 else
        "Ñ…Ğ¾Ñ€Ğ¾ÑˆĞµĞµ"             if score > 36 else
        "Ğ¿Ñ€Ğ¸ĞµĞ¼Ğ»ĞµĞ¼Ğ¾Ğµ"          if score > 30 else
        "Ğ·Ğ°Ğ¼ĞµÑ‚Ğ½Ğ°Ñ Ğ´ĞµĞ³Ñ€Ğ°Ğ´Ğ°Ñ†Ğ¸Ñ"
    )
    print(f"    PSNR: {score:.1f} dB â€” {quality_label}")

    return True


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Ğ’Ğ˜Ğ”Ğ•Ğ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def process_video(input_path: Path, output_path: Path, aggressive: bool = False) -> bool:
    if not has_tool("ffmpeg"):
        print("    [!] ffmpeg Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½")
        return False

    meta_clear = [
        "-metadata", "title=", "-metadata", "comment=",
        "-metadata", "description=", "-metadata", "creation_time=",
        "-metadata", "encoder=", "-metadata", "software=",
        "-metadata", "artist=", "-metadata", "copyright=",
        "-metadata:s", "handler_name=", "-metadata:s", "vendor_id=",
    ]
    base = ["-map_metadata", "-1", "-map_chapters", "-1",
            *meta_clear, "-fflags", "+bitexact",
            "-flags:v", "+bitexact", "-flags:a", "+bitexact"]

    if aggressive:
        cmd = ["ffmpeg", "-y", "-i", str(input_path), *base,
               "-c:v", "libx264", "-crf", "18", "-preset", "slow",
               "-c:a", "aac", "-b:a", "192k", str(output_path)]
        print("    [ffmpeg] ĞŸĞµÑ€ĞµĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ + Ğ¾Ñ‡Ğ¸ÑÑ‚ĞºĞ° Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…...")
    else:
        cmd = ["ffmpeg", "-y", "-i", str(input_path), *base,
               "-c", "copy", str(output_path)]
        print("    [ffmpeg] Stream copy + Ğ¾Ñ‡Ğ¸ÑÑ‚ĞºĞ° Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…...")

    ok, err = run(cmd)
    if not ok:
        print(f"    [!] ffmpeg: {err[-300:]}")
        return False

    if has_tool("exiftool"):
        run(["exiftool", "-all=", "-overwrite_original", str(output_path)])
    return True


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  ĞĞ£Ğ”Ğ˜Ğ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def process_audio(input_path: Path, output_path: Path) -> bool:
    try:
        from mutagen import File as MutagenFile
        shutil.copy2(input_path, output_path)
        audio = MutagenFile(output_path)
        if audio:
            audio.delete()
            audio.save()
            print("    [mutagen] ĞÑƒĞ´Ğ¸Ğ¾-Ñ‚ĞµĞ³Ğ¸ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ñ‹")
            return True
    except ImportError:
        print("    [!] pip install mutagen")
    return False


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Ğ¡Ğ ĞĞ’ĞĞ•ĞĞ˜Ğ• ĞœĞ•Ğ¢ĞĞ”ĞĞĞĞ«Ğ¥
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def compare_metadata(original: Path, cleaned: Path):
    if not has_tool("exiftool"):
        return
    TECHNICAL = {
        "SourceFile", "ExifToolVersion", "FileName", "Directory",
        "FileSize", "FileModifyDate", "FileAccessDate", "FileCreateDate",
        "FilePermissions", "FileType", "FileTypeExtension", "MIMEType",
        "ImageWidth", "ImageHeight", "ImageSize", "Megapixels",
        "BitDepth", "ColorType", "Compression", "Filter", "Interlace",
        "EncodingProcess", "BitsPerSample", "ColorComponents",
        "YCbCrSubSampling", "Duration", "AvgBitrate",
    }

    def get_tags(p):
        r = subprocess.run(["exiftool", "-j", str(p)],
                           capture_output=True, text=True)
        try:
            return json.loads(r.stdout)[0] if r.stdout else {}
        except Exception:
            return {}

    before = get_tags(original)
    after = get_tags(cleaned)
    removed = set(before.keys()) - set(after.keys())
    remaining = {k: v for k, v in after.items() if k not in TECHNICAL}

    print(f"\n  ğŸ“Š ĞœĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ:")
    print(f"     Ğ”Ğ¾: {len(before)} Ñ‚ĞµĞ³Ğ¾Ğ²  â†’  ĞŸĞ¾ÑĞ»Ğµ: {len(after)} Ñ‚ĞµĞ³Ğ¾Ğ²  "
          f"(ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¾: {len(removed)})")

    if remaining:
        print(f"  âš ï¸  ĞÑÑ‚Ğ°Ğ»Ğ¾ÑÑŒ: {', '.join(sorted(remaining.keys()))}")
    else:
        print(f"  âœ“  ĞœĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑÑ‚ÑŒÑ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ñ‹")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ Ğ—ĞĞ’Ğ˜Ğ¡Ğ˜ĞœĞĞ¡Ğ¢Ğ•Ğ™
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def check_deps():
    print("Ğ—Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸:\n")
    print("  Ğ’Ğ½ĞµÑˆĞ½Ğ¸Ğµ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹:")
    for tool, desc in [("ffmpeg", "Ğ²Ğ¸Ğ´ĞµĞ¾"), ("exiftool", "Ğ¿Ğ¾Ğ»Ğ½Ğ°Ñ Ğ¾Ñ‡Ğ¸ÑÑ‚ĞºĞ° Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…")]:
        st = "âœ“" if has_tool(tool) else "âœ—"
        print(f"    {st} {tool:<12} â€” {desc}")

    print("\n  Python Ğ¿Ğ°ĞºĞµÑ‚Ñ‹:")
    pkgs = [
        ("PIL",      "Pillow",   "Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ (Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾)"),
        ("numpy",    "numpy",    "Ğ°Ñ‚Ğ°ĞºĞ¸ Ğ½Ğ° watermark (Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾)"),
        ("scipy",    "scipy",    "DCT Ğ¸ geometric Ğ°Ñ‚Ğ°ĞºĞ¸"),
        ("pywt",     "PyWavelets","wavelet Ğ°Ñ‚Ğ°ĞºĞ°"),
        ("mutagen",  "mutagen",  "Ğ°ÑƒĞ´Ğ¸Ğ¾"),
    ]
    for mod, pkg, desc in pkgs:
        try:
            __import__(mod)
            print(f"    âœ“ {pkg:<12} â€” {desc}")
        except ImportError:
            print(f"    âœ— {pkg:<12} â€” pip install {pkg}  ({desc})")
    print()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Ğ¡ĞĞœĞĞ¡Ğ¢ĞĞ¯Ğ¢Ğ•Ğ›Ğ¬ĞĞĞ¯ ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ WATERMARK / AI-Ğ”Ğ•Ğ¢Ğ•ĞšĞ¦Ğ˜Ğ¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class WatermarkAnalyzer:
    """
    Ğ›Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸ invisible watermark Ğ¸ AI-Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸.
    ĞœĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ¸Ğ· Ğ°ĞºĞ°Ğ´ĞµĞ¼Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ»Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ñ‹ Ğ¿Ğ¾ steganalysis Ğ¸ media forensics.
    """

    def analyze(self, path: Path, reference_path: Path = None) -> dict:
        """
        ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ñ„Ğ°Ğ¹Ğ»Ğ°.
        reference_path â€” Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ» Ğ´Ğ¾ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ (Ğ´Ğ»Ñ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ).
        """
        if not HAS_PIL:
            print("[!] ĞÑƒĞ¶ĞµĞ½ Pillow")
            return {}

        with Image.open(path) as img:
            img = img.convert("RGB")
            arr = img_to_array(img)

        results = {}
        print(f"\n{'â”'*55}")
        print(f"  ĞĞĞĞ›Ğ˜Ğ—: {path.name}")
        print(f"{'â”'*55}")

        results["dct_anomaly"]    = self._check_dct_anomaly(arr)
        results["lsb_entropy"]    = self._check_lsb_entropy(arr)
        results["noise_floor"]    = self._check_noise_floor(arr)
        results["frequency_dist"] = self._check_frequency_distribution(arr)
        results["pixel_stats"]    = self._check_pixel_statistics(arr)

        if reference_path and reference_path.exists():
            with Image.open(reference_path) as ref:
                ref_arr = img_to_array(ref.convert("RGB"))
            results["diff_analysis"] = self._diff_analysis(arr, ref_arr)

        self._print_report(results)
        return results

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 1. DCT-Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»Ğ¸Ğ¸ (Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¸Ğ· JPEG steganalysis)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _check_dct_anomaly(self, arr: np.ndarray) -> dict:
        """
        ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ DCT-ĞºĞ¾ÑÑ„Ñ„Ğ¸Ñ†Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ² Ğ±Ğ»Ğ¾ĞºĞ¾Ğ² 8Ã—8.
        Watermarks Ğ¸ÑĞºĞ°Ğ¶Ğ°ÑÑ‚ ĞµÑÑ‚ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğµ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ ĞºĞ¾ÑÑ„Ñ„Ğ¸Ñ†Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ².
        """
        if not HAS_SCIPY:
            return {"available": False}

        from scipy.fft import dct as scipy_dct

        h, w = arr.shape[:2]
        channel = arr[:, :, 0]  # Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Y-ĞºĞ°Ğ½Ğ°Ğ» (ÑÑ€ĞºĞ¾ÑÑ‚ÑŒ)
        coeffs = []

        for y in range(0, h - 8, 8):
            for x in range(0, w - 8, 8):
                block = channel[y:y+8, x:x+8]
                dct_block = scipy_dct(scipy_dct(block.T, norm='ortho').T, norm='ortho')
                # Ğ¡Ñ€ĞµĞ´Ğ½Ğ¸Ğµ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ñ‹ (Ğ·Ğ¾Ğ½Ğ° watermark)
                coeffs.extend(dct_block[1:4, 1:4].flatten().tolist())

        coeffs = np.array(coeffs)

        # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ
        mean = float(np.mean(coeffs))
        std  = float(np.std(coeffs))
        kurt = float(self._kurtosis(coeffs))

        # Ğ•ÑÑ‚ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ¸Ğ¼ĞµÑÑ‚ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ½Ñ‹Ğ¹ ÑĞºÑÑ†ĞµÑÑ ~3-6
        # Watermarked Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ñ‡Ğ°ÑÑ‚Ğ¾ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ÑĞºÑÑ†ĞµÑÑ
        anomaly = abs(kurt - 4.5) > 3.0

        return {
            "mean": round(mean, 4),
            "std":  round(std, 4),
            "kurtosis": round(kurt, 4),
            "anomaly_detected": anomaly,
            "label": "âš ï¸  DCT-Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»Ğ¸Ñ (Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶ĞµĞ½ watermark)" if anomaly else "âœ“  DCT Ğ½Ğ¾Ñ€Ğ¼Ğ°"
        }

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 2. LSB-ÑĞ½Ñ‚Ñ€Ğ¾Ğ¿Ğ¸Ñ (Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ¼Ğ»Ğ°Ğ´ÑˆĞ¸Ñ… Ğ±Ğ¸Ñ‚Ğ¾Ğ²)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _check_lsb_entropy(self, arr: np.ndarray) -> dict:
        """
        LSB (least significant bits) â€” ĞºĞ»Ğ°ÑÑĞ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ ĞºĞ°Ğ½Ğ°Ğ» ÑÑ‚ĞµĞ³Ğ°Ğ½Ğ¾Ğ³Ñ€Ğ°Ñ„Ğ¸Ğ¸.
        SynthID Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ñ‹ LSB-embedding Ğ² Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ¼ Ğ´Ğ¾Ğ¼ĞµĞ½Ğµ.
        Ğ’Ñ‹ÑĞ¾ĞºĞ°Ñ ÑĞ½Ñ‚Ñ€Ğ¾Ğ¿Ğ¸Ñ LSB â†’ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°Ğº Ğ²ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ….
        """
        lsb = (arr.astype(np.uint8) & 1).flatten()

        # Ğ­Ğ½Ñ‚Ñ€Ğ¾Ğ¿Ğ¸Ñ Ğ¨ĞµĞ½Ğ½Ğ¾Ğ½Ğ°
        p1 = np.mean(lsb)
        p0 = 1.0 - p1
        if p0 > 0 and p1 > 0:
            entropy = -(p0 * np.log2(p0) + p1 * np.log2(p1))
        else:
            entropy = 0.0

        # ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ°Ñ ÑĞ½Ñ‚Ñ€Ğ¾Ğ¿Ğ¸Ñ = 1.0 (Ñ€Ğ°Ğ²Ğ½Ğ¾Ğ¼ĞµÑ€Ğ½Ğ¾Ğµ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ)
        # Ğ•ÑÑ‚ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ: 0.85â€“0.98
        # LSB-watermarked: Ğ±Ğ»Ğ¸Ğ·ĞºĞ¾ Ğº 1.0 (ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ñ€Ğ°Ğ²Ğ½Ğ¾Ğ¼ĞµÑ€Ğ½Ğ¾)
        suspicious = entropy > 0.990

        return {
            "entropy": round(float(entropy), 6),
            "p1_ratio": round(float(p1), 4),
            "suspicious": suspicious,
            "label": "âš ï¸  LSB-ÑĞ½Ñ‚Ñ€Ğ¾Ğ¿Ğ¸Ñ Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾ Ğ²Ñ‹ÑĞ¾ĞºĞ°Ñ" if suspicious else "âœ“  LSB Ğ½Ğ¾Ñ€Ğ¼Ğ°"
        }

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 3. ĞĞ½Ğ°Ğ»Ğ¸Ğ· ÑˆÑƒĞ¼Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ»Ğ°
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _check_noise_floor(self, arr: np.ndarray) -> dict:
        """
        Ğ˜Ğ˜-Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ¸Ğ¼ĞµÑÑ‚ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ½Ñ‹Ğ¹ ÑˆÑƒĞ¼Ğ¾Ğ²Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ÑŒ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚ ĞºĞ°Ğ¼ĞµÑ€.
        Diffusion-Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ ÑĞ¾Ğ·Ğ´Ğ°ÑÑ‚ "ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ñ‡Ğ¸ÑÑ‚Ñ‹Ğ¹" Ğ¸Ğ»Ğ¸ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ ÑˆÑƒĞ¼.
        """
        if not HAS_SCIPY:
            return {"available": False}

        # Ğ’Ñ‹ÑĞ¾ĞºĞ¾Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ½Ñ‹Ğ¹ Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ğº (ÑƒĞ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ½Ğ¸Ğ·ĞºĞ¾Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ½ÑƒÑ ÑĞ¾ÑÑ‚Ğ°Ğ²Ğ»ÑÑÑ‰ÑƒÑ)
        blurred = ndimage.gaussian_filter(arr, sigma=2)
        residual = arr - blurred

        noise_std  = float(np.std(residual))
        noise_mean = float(np.mean(np.abs(residual)))

        # SNR
        signal_std = float(np.std(arr))
        snr = signal_std / (noise_std + 1e-10)

        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ½Ğ° ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾ÑÑ‚ÑŒ ÑˆÑƒĞ¼Ğ° (FFT)
        fft = np.fft.fft2(residual[:, :, 0])
        fft_magnitude = np.abs(np.fft.fftshift(fft))
        # ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ¸Ğº â€” ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ ÑˆÑƒĞ¼ Ğ´Ğ°ÑÑ‚ Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ğ¹ Ğ¿Ğ¸Ğº
        fft_peak_ratio = float(np.max(fft_magnitude) / (np.mean(fft_magnitude) + 1e-10))

        structured = fft_peak_ratio > 50  # ÑĞ¼Ğ¿Ğ¸Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¿Ğ¾Ñ€Ğ¾Ğ³

        return {
            "noise_std": round(noise_std, 4),
            "snr": round(snr, 4),
            "fft_peak_ratio": round(fft_peak_ratio, 2),
            "structured_noise": structured,
            "label": "âš ï¸  Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ ÑˆÑƒĞ¼ (Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°Ğº WM)" if structured else "âœ“  Ğ¨ÑƒĞ¼ ĞµÑÑ‚ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¹"
        }

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 4. ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _check_frequency_distribution(self, arr: np.ndarray) -> dict:
        """
        ĞĞ½Ğ°Ğ»Ğ¸Ğ· ÑĞ¿ĞµĞºÑ‚Ñ€Ğ° Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ.
        Ğ˜Ğ˜-Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ñ‹ Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑÑÑ‚ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ½Ñ‹Ğµ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ Ğ² Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ½Ğ¾Ğ¼ Ğ´Ğ¾Ğ¼ĞµĞ½Ğµ.
        Ref: Corvi et al. "Intriguing Properties of Diffusion Models" (2023)
        """
        fft2d = np.fft.fft2(arr[:, :, 0])
        magnitude = np.abs(np.fft.fftshift(fft2d))
        h, w = magnitude.shape
        cy, cx = h // 2, w // 2

        # Ğ­Ğ½ĞµÑ€Ğ³Ğ¸Ñ Ğ² Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ½Ñ‹Ñ… Ğ·Ğ¾Ğ½Ğ°Ñ…
        def ring_energy(r_min, r_max):
            y, x = np.ogrid[:h, :w]
            dist = np.sqrt((y - cy)**2 + (x - cx)**2)
            mask = (dist >= r_min) & (dist < r_max)
            return float(np.sum(magnitude[mask]**2))

        low  = ring_energy(0,  min(cy, cx) * 0.1)
        mid  = ring_energy(min(cy, cx) * 0.1, min(cy, cx) * 0.4)
        high = ring_energy(min(cy, cx) * 0.4, min(cy, cx))

        total = low + mid + high + 1e-10
        low_r  = low  / total
        mid_r  = mid  / total
        high_r = high / total

        return {
            "low_freq_ratio":  round(low_r, 4),
            "mid_freq_ratio":  round(mid_r, 4),
            "high_freq_ratio": round(high_r, 4),
            "label": f"Ğ¡Ğ¿ĞµĞºÑ‚Ñ€: low={low_r:.1%} mid={mid_r:.1%} high={high_r:.1%}"
        }

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 5. Ğ‘Ğ°Ğ·Ğ¾Ğ²Ğ°Ñ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¿Ğ¸ĞºÑĞµĞ»ĞµĞ¹
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _check_pixel_statistics(self, arr: np.ndarray) -> dict:
        return {
            "mean":   round(float(np.mean(arr)), 2),
            "std":    round(float(np.std(arr)), 2),
            "min":    int(np.min(arr)),
            "max":    int(np.max(arr)),
            "label":  f"Î¼={np.mean(arr):.1f} Ïƒ={np.std(arr):.1f}"
        }

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 6. ĞŸĞ¾Ğ¿Ğ¸ĞºÑĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ (ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _diff_analysis(self, arr: np.ndarray, ref: np.ndarray) -> dict:
        if arr.shape != ref.shape:
            return {"error": "Ğ Ğ°Ğ·Ğ½Ñ‹Ğ¹ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹"}

        diff = arr.astype(float) - ref.astype(float)
        psnr_val = psnr(ref, arr)
        max_diff = float(np.max(np.abs(diff)))
        mean_diff = float(np.mean(np.abs(diff)))

        return {
            "psnr_db":   round(psnr_val, 2),
            "max_diff":  round(max_diff, 2),
            "mean_diff": round(mean_diff, 4),
            "label": f"PSNR={psnr_val:.1f} dB, Ğ¼Ğ°ĞºÑ.Ğ¾Ñ‚ĞºĞ».={max_diff:.1f}, ÑÑ€.Ğ¾Ñ‚ĞºĞ».={mean_diff:.4f}"
        }

    def _kurtosis(self, x: np.ndarray) -> float:
        mean = np.mean(x)
        std  = np.std(x)
        if std == 0:
            return 0.0
        return float(np.mean(((x - mean) / std) ** 4))

    def _print_report(self, results: dict):
        print()
        checks = [
            ("DCT-Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·",    results.get("dct_anomaly",    {})),
            ("LSB-ÑĞ½Ñ‚Ñ€Ğ¾Ğ¿Ğ¸Ñ",  results.get("lsb_entropy",    {})),
            ("Ğ¨ÑƒĞ¼Ğ¾Ğ²Ğ¾Ğ¹ Ğ¿Ğ¾Ğ»",   results.get("noise_floor",    {})),
            ("Ğ¡Ğ¿ĞµĞºÑ‚Ñ€",        results.get("frequency_dist", {})),
            ("Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°",    results.get("pixel_stats",    {})),
        ]
        for name, r in checks:
            if r.get("available") is False:
                print(f"  {name:<16} â€” Ğ½Ğµ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½ (Ğ½ÑƒĞ¶ĞµĞ½ scipy)")
            else:
                print(f"  {name:<16} â€” {r.get('label', 'â€”')}")

        if "diff_analysis" in results:
            print(f"  {'Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ':<16} â€” {results['diff_analysis'].get('label', 'â€”')}")

        # ĞĞ±Ñ‰Ğ¸Ğ¹ Ğ²ĞµÑ€Ğ´Ğ¸ĞºÑ‚
        flags = sum([
            results.get("dct_anomaly",  {}).get("anomaly_detected", False),
            results.get("lsb_entropy",  {}).get("suspicious", False),
            results.get("noise_floor",  {}).get("structured_noise", False),
        ])
        print()
        if flags == 0:
            print("  âœ… ĞŸÑ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ² watermark Ğ½Ğµ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ (Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·)")
        elif flags == 1:
            print(f"  ğŸŸ¡ Ğ¡Ğ»Ğ°Ğ±Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸ ({flags}/3 Ğ¸Ğ½Ğ´Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ğ°) â€” Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ Ğ½Ğ¾Ñ€Ğ¼Ğ°")
        else:
            print(f"  ğŸ”´ ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ñ‹ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸ watermark ({flags}/3 Ğ¸Ğ½Ğ´Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ğ°)")
        print(f"{'â”'*55}")


IMAGE_EXTS = {".jpg", ".jpeg", ".png", ".gif", ".tiff", ".tif",
              ".bmp", ".webp", ".avif", ".heic", ".heif"}
VIDEO_EXTS = {".mp4", ".mov", ".avi", ".mkv", ".webm",
              ".flv", ".wmv", ".m4v", ".mts", ".m2ts"}
AUDIO_EXTS = {".mp3", ".flac", ".ogg", ".m4a", ".wav", ".aiff", ".wma"}

WM_METHODS = ["ensemble", "gaussian", "dct", "wavelet",
              "photometric", "geometric", "fgsm", "median", "jpeg"]


def main():
    parser = argparse.ArgumentParser(
        description="Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… + Ğ°Ñ‚Ğ°ĞºĞ¸ Ğ½Ğ° invisible watermarks",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=f"""
ĞœĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ°Ñ‚Ğ°ĞºĞ¸ Ğ½Ğ° watermark (--wm-method):
  ensemble    â€” Ğ²ÑĞµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ²Ğ¼ĞµÑÑ‚Ğµ (Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ)
  gaussian    â€” Ğ³Ğ°ÑƒÑÑĞ¾Ğ²ÑĞºĞ¸Ğ¹ ÑˆÑƒĞ¼ (Stirmark)
  dct         â€” Ğ²Ğ¾Ğ·Ğ¼ÑƒÑ‰ĞµĞ½Ğ¸Ğµ DCT-ĞºĞ¾ÑÑ„Ñ„Ğ¸Ñ†Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ²
  wavelet     â€” ÑˆÑƒĞ¼ Ğ² Ğ²ĞµĞ¹Ğ²Ğ»ĞµÑ‚-Ğ´Ğ¾Ğ¼ĞµĞ½Ğµ (DWT)
  photometric â€” ÑÑ€ĞºĞ¾ÑÑ‚ÑŒ/ĞºĞ¾Ğ½Ñ‚Ñ€Ğ°ÑÑ‚/Ğ³Ğ°Ğ¼Ğ¼Ğ°
  geometric   â€” Ğ¼Ğ¸ĞºÑ€Ğ¾-Ğ´ĞµÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¸ĞºÑĞµĞ»ĞµĞ¹
  fgsm        â€” adversarial noise (FGSM-style)
  median      â€” Ğ¼ĞµĞ´Ğ¸Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€
  jpeg        â€” Ğ´Ğ²Ğ¾Ğ¹Ğ½Ğ¾Ğµ JPEG-ÑĞ¶Ğ°Ñ‚Ğ¸Ğµ

ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹:
  python clean_metadata.py photo.jpg
  python clean_metadata.py photo.jpg --wm-method ensemble --wm-strength 0.5 -c -v
  python clean_metadata.py ./dataset --wm-method ensemble -a -r
  python clean_metadata.py video.mp4 -a
  python clean_metadata.py --check-deps
        """
    )
    parser.add_argument("inputs", nargs="*")
    parser.add_argument("-o", "--output", default="./cleaned")
    parser.add_argument("-a", "--aggressive", action="store_true",
                        help="ĞĞ³Ñ€ĞµÑÑĞ¸Ğ²Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼ (Ğ¿ĞµÑ€ĞµĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ²Ğ¸Ğ´ĞµĞ¾, Ğ¿ĞµÑ€ĞµÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¸ĞºÑĞµĞ»ĞµĞ¹)")
    parser.add_argument("-r", "--randomize-timestamps", action="store_true",
                        help="Ğ Ğ°Ğ½Ğ´Ğ¾Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ timestamps Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²")
    parser.add_argument("-c", "--compare", action="store_true",
                        help="Ğ¡Ñ€Ğ°Ğ²Ğ½Ğ¸Ñ‚ÑŒ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ¾/Ğ¿Ğ¾ÑĞ»Ğµ (Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ exiftool)")
    parser.add_argument("-v", "--verbose", action="store_true",
                        help="ĞŸĞ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ²Ğ¾Ğ´")
    parser.add_argument("--wm-method", default="ensemble",
                        choices=WM_METHODS, metavar="METHOD",
                        help=f"ĞœĞµÑ‚Ğ¾Ğ´ Ğ°Ñ‚Ğ°ĞºĞ¸ Ğ½Ğ° watermark [{', '.join(WM_METHODS)}]")
    parser.add_argument("--wm-strength", type=float, default=0.5,
                        metavar="0.0â€“1.0",
                        help="Ğ¡Ğ¸Ğ»Ğ° Ğ°Ñ‚Ğ°ĞºĞ¸: 0.3=Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ°Ñ, 0.5=Ğ±Ğ°Ğ»Ğ°Ğ½Ñ, 0.8=Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ°Ñ")
    parser.add_argument("--no-watermark-attack", action="store_true",
                        help="Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ, Ğ±ĞµĞ· Ğ°Ñ‚Ğ°ĞºĞ¸ Ğ½Ğ° watermark")
    parser.add_argument("--check-deps", action="store_true")
    parser.add_argument("--analyze", action="store_true",
                        help="ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ½Ğ° Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸ watermark (Ğ´Ğ¾ Ğ¸ Ğ¿Ğ¾ÑĞ»Ğµ)")

    args = parser.parse_args()

    if args.check_deps or not args.inputs:
        check_deps()
        if not args.inputs:
            parser.print_help()
            return

    if not (0.0 <= args.wm_strength <= 1.0):
        print("[!] --wm-strength Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ Ğ¾Ñ‚ 0.0 Ğ´Ğ¾ 1.0")
        sys.exit(1)

    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)

    files = []
    for inp in args.inputs:
        p = Path(inp)
        if p.is_dir():
            for ext_set in [IMAGE_EXTS, VIDEO_EXTS, AUDIO_EXTS]:
                for e in ext_set:
                    files.extend(p.rglob(f"*{e}"))
                    files.extend(p.rglob(f"*{e.upper()}"))
        elif p.is_file():
            files.append(p)
        else:
            print(f"[!] ĞĞµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾: {inp}")

    files = sorted(set(files))
    if not files:
        print("ĞĞµÑ‚ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµĞ¼Ñ‹Ñ… Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ².")
        return

    print(f"Ğ¤Ğ°Ğ¹Ğ»Ğ¾Ğ²:        {len(files)}")
    print(f"WM-Ğ°Ñ‚Ğ°ĞºĞ°:      {'Ğ½ĞµÑ‚ (--no-watermark-attack)' if args.no_watermark_attack else args.wm_method}")
    if not args.no_watermark_attack:
        print(f"WM-strength:   {args.wm_strength}")
    print(f"Ğ’Ñ‹Ğ²Ğ¾Ğ´:         {output_dir.resolve()}\n")

    analyzer = WatermarkAnalyzer()

    ok_count = 0
    for f in files:
        ext = f.suffix.lower()
        output_path = output_dir / f"{f.stem}_clean{f.suffix}"
        print(f"\nâ†’ {f.name}")

        if args.analyze and ext in IMAGE_EXTS:
            print(f"  [ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ”Ğ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸]")
            analyzer.analyze(f)

        ok = False
        if ext in IMAGE_EXTS:
            if args.no_watermark_attack:
                # Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
                if has_tool("exiftool"):
                    r, _ = run(["exiftool", "-all=", "-overwrite_original",
                                "-o", str(output_path), str(f)])
                    ok = r
                if not ok:
                    ok = strip_jpeg(f, output_path) if ext in (".jpg", ".jpeg") \
                         else strip_png(f, output_path)
            else:
                ok = process_image(
                    f, output_path,
                    wm_method=args.wm_method,
                    wm_strength=args.wm_strength,
                    aggressive_meta=args.aggressive,
                    verbose=args.verbose
                )
        elif ext in VIDEO_EXTS:
            ok = process_video(f, output_path, args.aggressive)
        elif ext in AUDIO_EXTS:
            ok = process_audio(f, output_path)

        if ok:
            if args.analyze and ext in IMAGE_EXTS and output_path.exists():
                print(f"  [ĞĞ½Ğ°Ğ»Ğ¸Ğ· ĞŸĞĞ¡Ğ›Ğ• Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸]")
                analyzer.analyze(output_path, reference_path=f)
            if args.randomize_timestamps:
                randomize_timestamps(output_path)
                print("    [ts] Timestamps Ñ€Ğ°Ğ½Ğ´Ğ¾Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹")
            if args.compare:
                compare_metadata(f, output_path)
            size_b = f.stat().st_size
            size_a = output_path.stat().st_size
            print(f"  âœ“ {size_b/1024:.1f} KB â†’ {size_a/1024:.1f} KB")
            ok_count += 1

    print(f"\n{'â•'*55}")
    print(f"âœ“ ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ¾: {ok_count}/{len(files)}")
    print(f"  Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹: {output_dir.resolve()}")

    if not has_tool("exiftool"):
        print("\nğŸ’¡ Ğ”Ğ»Ñ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğ¹ Ğ¾Ñ‡Ğ¸ÑÑ‚ĞºĞ¸ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ ExifTool: https://exiftool.org")
    if not HAS_WAVELETS:
        print("ğŸ’¡ Ğ”Ğ»Ñ wavelet-Ğ°Ñ‚Ğ°ĞºĞ¸: pip install PyWavelets")
    if not HAS_SCIPY:
        print("ğŸ’¡ Ğ”Ğ»Ñ DCT/geometric Ğ°Ñ‚Ğ°Ğº: pip install scipy")


if __name__ == "__main__":
    main()

